'''
File: infer_and_save.py
Author: moye12325
Description: 1:æ¨¡å‹æ¨ç†çš„ä»£ç ï¼Œå›¾åƒ256*256
Created: $TIME
Version: v1.0

ä¿®æ”¹è®°å½•:
Date        Author        Modification Content
2025/2/19   moye12325     æ·»åŠ æ–‡ä»¶æ³¨é‡Š
'''

import os
import torch
import glob
from PIL import Image
from torchvision import transforms
from torchvision.transforms import InterpolationMode
from NestedUNet import NestedUNet
from config import Config

# ======================= è®¾å¤‡é…ç½® =======================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# ======================= å›¾åƒé¢„å¤„ç† =======================
def get_transform(image_size=Config.IMAGE_SIZE):
    """è¿”å›å›¾åƒé¢„å¤„ç† transformï¼ŒåŒ…å« Resizeã€ToTensor ä¸ Normalize"""
    return transforms.Compose([
        transforms.Resize(image_size, interpolation=InterpolationMode.BILINEAR),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])

# ======================= åŠ è½½æ¨¡å‹ =======================
def load_model(model_path, num_classes=Config.TRAIN_PARAMS['num_classes'], input_channels=3):
    """åŠ è½½ PyTorch é¢„è®­ç»ƒæ¨¡å‹"""
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model file not found: {model_path}")

    model = NestedUNet(num_classes=num_classes, input_channels=input_channels).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device), strict=False)
    model.eval()
    print(f"âœ… Model loaded from: {model_path}")
    return model

# ======================= è¿›è¡Œæ¨ç† =======================
def segment_images(model, image_dir, output_dir, image_size=Config.IMAGE_SIZE):
    """
    è¯»å– `image_dir` ä¸­çš„æ‰€æœ‰å›¾ç‰‡ï¼Œè¿›è¡Œåˆ†å‰²ï¼Œå¹¶ä¿å­˜åˆ° `output_dir`
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    transform = get_transform(image_size)

    # å¤„ç†æ‰€æœ‰å›¾ç‰‡
    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    if not image_files:
        print(f"âš ï¸ No valid images found in {image_dir}")
        return

    print(f"ğŸ“‚ Processing {len(image_files)} images in {image_dir}...")

    for filename in image_files:
        filepath = os.path.join(image_dir, filename)

        try:
            # è¯»å–å›¾åƒï¼Œå¹¶è½¬æ¢ä¸º RGB
            image = Image.open(filepath).convert('RGB')
            # å°†é¢„å¤„ç†åçš„å›¾åƒæ‰©å±•ä¸º batch æ ¼å¼
            input_tensor = transform(image).unsqueeze(0).to(device)

            with torch.no_grad():
                # æ¨ç†é˜¶æ®µï¼Œè¿›è¡Œå‰å‘ä¼ æ’­ï¼Œè¾“å‡ºä¸º [batch, num_classes, H, W]
                outputs = model(input_tensor)
                prediction = torch.argmax(outputs, dim=1).squeeze(0)

            # ä¿å­˜åˆ†å‰²ç»“æœ
            output_filename = f"{os.path.splitext(filename)[0]}_segmentation.png"
            output_path = os.path.join(output_dir, output_filename)

            # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾åˆ†å‰²ä¸ºäºŒå€¼ï¼Œä¹Ÿå¯ä»¥æ ¹æ®å…·ä½“ç±»åˆ«è¿›è¡Œä¸åŒæ˜ å°„
            pred_img = (prediction.byte().cpu().numpy() * 255)
            Image.fromarray(pred_img).save(output_path)

            print(f"âœ” Processed: {filename} â†’ {output_dir} {output_filename}")

        except Exception as e:
            print(f"âŒ Error processing {filename}: {e}")

# ä¸»æ‰§è¡Œä»£ç 
if __name__ == "__main__":

    # è‡ªåŠ¨è·å–æœ€æ–°æ¨¡å‹
    model_dir = Config.DATA_PATHS['model_save_dir']
    model_files = glob.glob(os.path.join(model_dir, "*.pth"))

    if not model_files:
        raise FileNotFoundError(f"No trained models found in {model_dir}")

    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºè·å–æœ€æ–°æ¨¡å‹
    model_files.sort(key=os.path.getmtime, reverse=True)
    model_path = model_files[0]

    # âœ… ç¡®ä¿ `num_classes` å’Œ `input_channels` è®¾ç½®æ­£ç¡®
    model = load_model(model_path)

    print(f"âœ… Load model â¡ï¸ {model_path}")

    # å®šä¹‰è¾“å…¥ç›®å½•å’Œè¾“å‡ºç›®å½•
    input_dirs = Config.DATA_PATHS['test_image_dirs']

    # æ ¹æ®æ¨¡å‹æ–‡ä»¶åç”Ÿæˆè¾“å‡ºç›®å½•åç§°
    model_filename = os.path.basename(model_path)
    base_output_dir = f"./result/segmentation_results_{os.path.splitext(model_filename)[0]}"
    print(f"ğŸ“‚ Expected output to â¡ï¸ {base_output_dir}")

    image_size = Config.IMAGE_SIZE

    for input_dir in input_dirs:
        output_dir = os.path.join(base_output_dir, os.path.basename(input_dir))
        segment_images(model, input_dir, output_dir, image_size)

    print(f"Segmentation results saved to: {base_output_dir}")