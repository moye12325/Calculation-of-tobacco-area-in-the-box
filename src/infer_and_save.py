'''
File: infer_and_save.py
Author: moye12325
Description: 1:æ¨¡å‹æ¨ç†çš„ä»£ç ï¼Œå›¾åƒ256*256
Created: $TIME
Version: v1.0

ä¿®æ”¹è®°å½•:
Date        Author        Modification Content
2025/2/19   moye12325     æ·»åŠ æ–‡ä»¶æ³¨é‡Š
'''

import os
import torch
import glob
from PIL import Image
from torchvision import transforms
from torchvision.transforms import InterpolationMode
from NestedUNet import NestedUNet
from config import Config

## æ¨ç†ä»£ç 

# ======================= è®¾å¤‡é…ç½® =======================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# ======================= å›¾åƒé¢„å¤„ç† =======================
def get_transform(image_size=(256, 256)):
    """è¿”å›å›¾åƒé¢„å¤„ç† transform"""
    return transforms.Compose([
        transforms.Resize(image_size, interpolation=InterpolationMode.BILINEAR),
        transforms.ToTensor()
    ])

# ======================= åŠ è½½æ¨¡å‹ =======================
def load_model(model_path, num_classes=2, input_channels=3):
    """åŠ è½½ PyTorch é¢„è®­ç»ƒæ¨¡å‹"""
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model file not found: {model_path}")

    model = NestedUNet(num_classes=num_classes, input_channels=input_channels).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device), strict=False)
    model.eval()
    print(f"âœ… Model loaded from: {model_path}")
    return model


# ======================= è¿›è¡Œæ¨ç† =======================
def segment_images(model, image_dir, output_dir, image_size=(256, 256)):
    """
    è¯»å– `image_dir` ä¸­çš„æ‰€æœ‰å›¾ç‰‡ï¼Œè¿›è¡Œåˆ†å‰²ï¼Œå¹¶ä¿å­˜åˆ° `output_dir`
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    transform = get_transform(image_size)

    # å¤„ç†æ‰€æœ‰å›¾ç‰‡
    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    if not image_files:
        print(f"âš ï¸ No valid images found in {image_dir}")
        return

    print(f"ğŸ“‚ Processing {len(image_files)} images in {image_dir}...")

    for filename in image_files:
        filepath = os.path.join(image_dir, filename)

        try:
            # è¯»å–å›¾åƒ + ç»´åº¦æ‰©å±•
            image = Image.open(filepath).convert('RGB')
            input_tensor = transform(image).unsqueeze(0).to(device)

            with torch.no_grad():
                # âœ… è¿›è¡Œæ¨ç† GPU ä¸Šè®¡ç®— `argmax`
                outputs = model(input_tensor)
                prediction = torch.argmax(outputs, dim=1).squeeze(0)

            # ä¿å­˜åˆ†å‰²ç»“æœ
            output_filename = f"{os.path.splitext(filename)[0]}_segmentation.png"
            output_path = os.path.join(output_dir, output_filename)

            # âœ… ç›´æ¥è½¬æ¢ `uint8`
            pred_img = prediction.byte().cpu().numpy() * 255
            Image.fromarray(pred_img).save(output_path)

            print(f"âœ” Processed: {filename} â†’ {output_dir} {output_filename}")

        except Exception as e:
            print(f"âŒ Error processing {filename}: {e}")

# ä¸»æ‰§è¡Œä»£ç 
if __name__ == "__main__":

    # è‡ªåŠ¨è·å–æœ€æ–°æ¨¡å‹
    model_dir = Config.DATA_PATHS['model_save_dir']
    model_files = glob.glob(os.path.join(model_dir, "*.pth"))

    if not model_files:
        raise FileNotFoundError(f"No trained models found in {model_dir}")

    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºè·å–æœ€æ–°æ¨¡å‹
    model_files.sort(key=os.path.getmtime, reverse=True)
    model_path = model_files[0]

    # âœ… ç¡®ä¿ `num_classes` å’Œ `input_channels` è®¾ç½®æ­£ç¡®
    model = load_model(model_path)

    print(f"âœ… Load model â¡ï¸ {model_path}")

    # å®šä¹‰è¾“å…¥ç›®å½•å’Œè¾“å‡ºç›®å½•
    input_dirs = Config.DATA_PATHS['test_image_dirs']

    # base_output_dir = './result/segmentation_results_V4_511'  # åŸºç¡€è¾“å‡ºç»“æœç›®å½•

    # ä»æ¨¡å‹æ–‡ä»¶åä¸­æå–ä¿¡æ¯
    model_filename = os.path.basename(model_path)
    base_output_dir = f"./result/segmentation_results_{os.path.splitext(model_filename)[0]}"
    print(f"ğŸ“‚ Expected output to â¡ï¸ {base_output_dir}")

    image_size = Config.IMAGE_SIZE

    for input_dir in input_dirs:
        output_dir = os.path.join(base_output_dir, os.path.basename(input_dir))
        segment_images(model, input_dir, output_dir, image_size)

    print(f"Segmentation results saved to: {base_output_dir}")